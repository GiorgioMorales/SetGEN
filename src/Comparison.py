import pickle
import omegaconf
import numpy as np
import matplotlib.pyplot as plt
from src.EquationLearning.Data.sympy_utils import *
from src.EquationLearning.Data.GenerateDatasets import DataLoader
from src.EquationLearning.Transformers.GenerateTransformerData import Dataset, evaluate_and_wrap
from src.EquationLearning.Data.dclasses import SimpleEquation
from src.EquationLearning.models.utilities_expressions import avoid_operations_between_constants, add_constant_identifier
from src.EquationLearning.Optimization.CoefficientFitting import FitGA

np.random.seed(7)  # Set seed

# Parameters
name = 'E2'
limits = [-20, 20]
clim = [-30, 30]
cfg = omegaconf.OmegaConf.load("./EquationLearning/Transformers/config.yaml")
training_dataset = Dataset(cfg.train_path, cfg.dataset_train, mode="train")
word2id = training_dataset.word2id

# Methods
methods = ['MST', 'NESYMRES', 'E2E', 'GPLEARN', 'PYSR']

# Load underlying equation
dataLoader = DataLoader(name=name, extrapolation=True)
X, Y, var_names, expr = dataLoader.X, dataLoader.Y, dataLoader.names, dataLoader.expr
print("Underlying function: " + str(expr))

# Analyze one variable at a time
for var in var_names:
    # Get skeleton for each variable present in the expression
    skeleton = numeric_to_placeholder(expr)
    for v in var_names:
        if v != var:
            skeleton = skeleton.subs(sp.sympify(v), sp.sympify('c'))
    skeleton2 = None
    while skeleton != skeleton2:
        skeleton2 = skeleton
        skeleton = avoid_operations_between_constants(skeleton)
        skeleton = numeric_to_placeholder(skeleton)
    skeleton = add_constant_identifier(skeleton)
    print('Analyzing variable ' + var + '. Skeleton: ')
    print('\t' + str(skeleton))

    # Sample coefficient values for the given skeleton
    coeff_dict = dict()
    for constant in skeleton.free_symbols:
        if 'c' in str(constant):
            coeff_dict[str(constant)] = constant

    eq = SimpleEquation(expr=skeleton, coeff_dict=coeff_dict, variables=[var])
    result = evaluate_and_wrap(eq, cfg.dataset_train, word2id, return_exprs=True)
    Xs, Ys, _, _, exprs = result

    # Analyze each of the 10 sampled expressions
    errors = np.zeros((Xs.shape[1], len(methods)))
    for it in range(Xs.shape[1]):
        Xi, Yi = Xs[:, it], Ys[:, it]
        print('\tIteration ' + str(it))
        print("\t|\tSampled expression: " + str(exprs[it]))

        # TODO: Load the skeletons generated by all the methods
        est_skeletons = [sp.sympify('c * x0 ** 2 + c * x0 + c')] * len(methods)

        for im, method in enumerate(methods):
            print("\t|\t\tUsing skeleton obtained by the " + method + " method: " + str(est_skeletons[im]))
            # Fit coefficients of the estimated skeletons
            problem = FitGA(est_skeletons[im], Xi, Yi, limits, clim)
            est_expr, error = problem.run()
            errors[it, im] = error
            print("\t|\t\t\tFitted expression: " + str(est_expr) + ". Error = " + str(np.round(error, 8)))

    # Save results
    np.save('output/metrics/comparison_' + name + '.npy', errors)

    # Create box plots for each method
    plt.figure()
    plt.boxplot(errors, labels=methods)
    plt.xlabel('Methods')
    plt.ylabel('Errors')
