import omegaconf
import sympy as sp
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import tukey_hsd
from src.utils import get_project_root
from src.EquationLearning.Data.dclasses import SimpleEquation
from src.EquationLearning.Data.GenerateDatasets import DataLoader
from src.EquationLearning.models.utilities_expressions import add_constant_identifier, get_skeletons
from src.EquationLearning.Optimization.CoefficientFitting import FitGA
from src.EquationLearning.Transformers.GenerateTransformerData import Dataset, evaluate_and_wrap


def tukeyLetters(pp, means=None, alpha=0.05):
    if len(pp.shape) == 1:
        # vector
        G = int(3 + np.sqrt(9 - 4 * (2 - len(pp)))) // 2
        ppp = .5 * np.eye(G)
        ppp[np.triu_indices(G, 1)] = pp
        pp = ppp + ppp.T
    conn = pp > alpha
    G = len(conn)
    if np.all(conn):
        return ['a' for _ in range(G)]
    conns = []
    for g1 in range(G):
        for g2 in range(g1 + 1, G):
            if conn[g1, g2]:
                conns.append((g1, g2))

    letters = [[] for _ in range(G)]
    nextletter = 0
    for g in range(G):
        if np.sum(conn[g, :]) == 1:
            letters[g].append(nextletter)
            nextletter += 1
    while len(conns):
        grp = set(conns.pop(0))
        for g in range(G):
            if all(conn[g, np.sort(list(grp))]):
                grp.add(g)
        for g in grp:
            letters[g].append(nextletter)
        for g in grp:
            for h in grp:
                if (g, h) in conns:
                    conns.remove((g, h))
        nextletter += 1

    if means is None:
        means = np.arange(G)
    means = np.array(means)
    groupmeans = []
    for k in range(nextletter):
        ingroup = [g for g in range(G) if k in letters[g]]
        groupmeans.append(means[np.array(ingroup)].mean())
    ordr = np.empty(nextletter, int)
    ordr[np.argsort(groupmeans)] = np.arange(nextletter)
    r = []
    for ltr in letters:
        lst = [chr(97 + ordr[x]) for x in ltr]
        lst.sort()
        r.append(''.join(lst))
    return r


np.random.seed(7)  # Set seed

# Parameters
name = 'E2'
clim = [-10, 10]
cfg = omegaconf.OmegaConf.load("./EquationLearning/Transformers/config.yaml")
training_dataset = Dataset(cfg.train_path, cfg.dataset_train, mode="train")
word2id = training_dataset.word2id

# Methods
methods = ['PYSR', 'TaylorGP', 'NESYMRES', 'E2E', 'MST']

# Load underlying equation
dataLoader = DataLoader(name=name, extrapolation=True)
X, Y, var_names, expr = dataLoader.X, dataLoader.Y, dataLoader.names, dataLoader.expr
limits = [dataLoader.limits[0][0] * 2, dataLoader.limits[0][1] * 2]
print("Underlying function: " + str(expr))

# Analyze one variable at a time
original_skeletons = get_skeletons(expr, var_names)
for iv, var in enumerate(var_names):
    if iv >= 0:
        # Get skeleton for each variable present in the expression
        skeleton = original_skeletons[iv]
        print('Analyzing variable ' + var + '. Skeleton: ')
        print('\t' + str(skeleton))

        # Sample coefficient values for the given skeleton
        coeff_dict = dict()
        for constant in skeleton.free_symbols:
            if 'c' in str(constant):
                coeff_dict[str(constant)] = constant

        eq = SimpleEquation(expr=skeleton, coeff_dict=coeff_dict, variables=[var])
        result = evaluate_and_wrap(eq, cfg.dataset_train, word2id, return_exprs=True, n_sets=30,
                                   xmin=dataLoader.limits[iv][0] * 2, xmax=dataLoader.limits[iv][1] * 2)
        Xs, Ys, _, _, exprs = result

        # Analyze each of the 10 sampled expressions
        errors = np.zeros((Xs.shape[1], len(methods)))
        for it in range(Xs.shape[1]):
            Xi, Yi = Xs[:, it], Ys[:, it]
            print('\tIteration ' + str(it))
            print("\t|\tSampled expression: " + str(exprs[it]))

            for im, method in enumerate(methods):
                # Load the expressions generated by each method
                path = str(get_project_root()) + "/output/LearnedEquations/" + name + "/" + method + ".txt"
                with open(path, "r") as myfile:
                    sk = myfile.read().splitlines()
                if method != 'MST':
                    # Get the skeleton for the current variable
                    est_skeletons = get_skeletons(expr=sp.sympify(sk[0]), var_names=var_names)
                    est_skeleton = est_skeletons[iv]
                else:
                    # In the case of the Multi-Set Transformer, it directly saves the skeletons
                    est_skeleton = get_skeletons(expr=sp.sympify(sk[iv]), var_names=var_names)[iv]
                    est_skeleton = add_constant_identifier(est_skeleton)[0]

                print("\t|\t\tUsing skeleton obtained by the " + method + " method: " + str(est_skeleton))
                # Fit coefficients of the estimated skeletons
                problem = FitGA(est_skeleton, Xi, Yi, limits, clim)
                est_expr, error = problem.run()
                errors[it, im] = error
                print("\t|\t\t\tFitted expression: " + str(est_expr) + ". Error = " + str(np.round(error, 8)))

        # Save results
        np.save(str(get_project_root()) + '/output/metrics/comparison_var-' + var + '_problem-' + name + '.npy', errors)

        # Create box plots for each method
        plt.figure()
        plt.boxplot(errors, labels=methods)
        plt.xlabel('Methods')
        plt.ylabel('Errors')

        # Perform Tukey Test
        columns = [errors[:, i] for i in range(errors.shape[1])]
        res = tukey_hsd(*columns)
        print("Tukey's HSD Pairwise Group Comparisons (Grouping)")
        print("___________________")
        print(methods)
        lett = tukeyLetters(res.pvalue)
        print(lett)
