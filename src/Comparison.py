import omegaconf
import sympy as sp
import numpy as np
from src.utils import get_project_root
import matplotlib.pyplot as plt
# from src.EquationLearning.Data.sympy_utils import *
from src.EquationLearning.Data.GenerateDatasets import DataLoader
from src.EquationLearning.Transformers.GenerateTransformerData import Dataset, evaluate_and_wrap
from src.EquationLearning.Data.dclasses import SimpleEquation
from src.EquationLearning.models.utilities_expressions import avoid_operations_between_constants, \
    add_constant_identifier, get_skeletons
from src.EquationLearning.Optimization.CoefficientFitting import FitGA

np.random.seed(7)  # Set seed

# Parameters
name = 'E3'
clim = [-10, 10]
cfg = omegaconf.OmegaConf.load("./EquationLearning/Transformers/config.yaml")
training_dataset = Dataset(cfg.train_path, cfg.dataset_train, mode="train")
word2id = training_dataset.word2id

# Methods
# methods = ['GPLEARN', 'PYSR', 'NESYMRES', 'E2E', 'MST']
methods = ['PYSR', 'NESYMRES', 'E2E', 'MST']

# Load underlying equation
dataLoader = DataLoader(name=name, extrapolation=True)
X, Y, var_names, expr = dataLoader.X, dataLoader.Y, dataLoader.names, dataLoader.expr
limits = [dataLoader.limits[0][0] * 2, dataLoader.limits[0][1] * 2]
print("Underlying function: " + str(expr))

# Analyze one variable at a time
original_skeletons = get_skeletons(expr, var_names)
for iv, var in enumerate(var_names):
    if iv == 0:
        # Get skeleton for each variable present in the expression
        skeleton = original_skeletons[iv]
        print('Analyzing variable ' + var + '. Skeleton: ')
        print('\t' + str(skeleton))

        # Sample coefficient values for the given skeleton
        coeff_dict = dict()
        for constant in skeleton.free_symbols:
            if 'c' in str(constant):
                coeff_dict[str(constant)] = constant

        eq = SimpleEquation(expr=skeleton, coeff_dict=coeff_dict, variables=[var])
        result = evaluate_and_wrap(eq, cfg.dataset_train, word2id, return_exprs=True)
        Xs, Ys, _, _, exprs = result

        # Analyze each of the 10 sampled expressions
        errors = np.zeros((Xs.shape[1], len(methods)))
        for it in range(Xs.shape[1]):
            Xi, Yi = Xs[:, it], Ys[:, it]
            print('\tIteration ' + str(it))
            print("\t|\tSampled expression: " + str(exprs[it]))

            for im, method in enumerate(methods):
                # Load the expressions generated by each method
                path = str(get_project_root()) + "/output/LearnedEquations/" + name + "/" + method + ".txt"
                with open(path, "r") as myfile:
                    sk = myfile.read().splitlines()
                if method != 'MST':
                    # Get the skeleton for the current variable
                    est_skeletons = get_skeletons(expr=sp.sympify(sk[0]), var_names=var_names)
                    est_skeleton = est_skeletons[iv]
                else:
                    # In the case of the Multi-Set Transformer, it directly saves the skeletons
                    est_skeleton = get_skeletons(expr=sp.sympify(sk[iv]), var_names=var_names)[iv]
                    est_skeleton = add_constant_identifier(est_skeleton)[0]
                print("\t|\t\tUsing skeleton obtained by the " + method + " method: " + str(est_skeleton))
                # Fit coefficients of the estimated skeletons
                problem = FitGA(est_skeleton, Xi, Yi, limits, clim)
                est_expr, error = problem.run()
                errors[it, im] = error
                print("\t|\t\t\tFitted expression: " + str(est_expr) + ". Error = " + str(np.round(error, 8)))

        # Save results
        np.save(str(get_project_root()) + '/output/metrics/comparison_var-' + var + '_problem-' + name + '.npy', errors)

        # Create box plots for each method
        plt.figure()
        plt.boxplot(errors, labels=methods)
        plt.xlabel('Methods')
        plt.ylabel('Errors')
